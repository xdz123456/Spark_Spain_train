# BD15 Prediction of Train Ticket Price in Spain

This file is the justification and manual for the code repository.
All Spark related codes are referenced to: https://spark.apache.org/
OR http://spark.apache.org/docs/latest/ml-classification-regression.html

!!! Note that if you are using jupyter notebook for running, you just need to run ```dataCleanCompilation.py``` and ```mlCompilation.py``` in order.
Otherwise, if you can run with submit mode, you can specify the output directory name. 

Our raw data set is too large to submit, so we will visit your office to give you our raw data set in a USB. Additionally, we will attach our experimental output repositories as well.

The directory BD15-paper-codes-2021 is the latex source codes of our report.

## Data Clean
Data clean is executed in four different python files for different purposes.

There are several files or directories in the output directory.
```correlation matrix.png``` is the pearson correlation matrix of the features.
```histogram.png``` is the histogram of price distribution, the vertical lines are the discretization .
```ml sample``` is the directory of final cleaned data for machine learning algorithms.
```sample``` is an intermidiate data set generated by ```dataClean1.py```
```sample column counts``` is the statistical counts of instances of all attributes.

### Terminal Commands - dataCleanCompilation.py
Execute all data clean operations in a row.
Example usage:
The command line parameter ```--dirName Directory``` is a repository for saving all data clean results. Note that it should take the raw data set named ```BD15 raw data.csv``` as input, this file should be in the same directory with the python files.
```bash
spark-submit dataClean1.py --dirName Result
```

### Terminal Commands - dataClean1.py
Single data clean operation can be executed individually as the required input file is in the output repository. 
Delete unwanted attributes, invalid rows; shrink data set.

Example usage:
The command line parameter ```--dirName Directory``` is a repository for saving the intermidiate cleaned data ```sample```.
```bash
spark-submit dataClean1.py --dirName Result
```

### Terminal Commands - dataClean2.py
Save number of attributes of columns for further data analysis.

Example usage:
The command line parameter ```--dirName Directory``` is a repository for reading the intermidiate cleaned data ```sample``` and saving the statistical counts of instances ```sample column counts```.
```bash
spark-submit dataClean2.py --dirName Result
```

### Terminal Commands - dataClean3.py
Reference for drawing histogram and vertical lines: https://blog.csdn.net/zengbowengood/article/details/108780582
Change data set for machine learning algorithms.

Example usage:
The command line parameter ```--dirName Directory``` is a repository for reading the intermidiate cleaned data ```sample``` and saving the final cleaned data set ```ml sample``` for machine learning classification algorithms. Additionally, it outputs the ```histogram.png```.
```bash
spark-submit dataClean3.py --dirName Result
```

### Terminal Commands - dataClean4.py
Reference for plotting correlation matrix: https://blog.csdn.net/zzw000000/article/details/81205027
Calculate pearson correlation matrix for features.

Example usage:
The command line parameter ```--dirName Directory``` is a repository for reading the cleaned data ```ml sample``` and saving the pearson correlation matrix ```correlation matrix.png```.
```bash
spark-submit dataClean4.py --dirName Result
```

## Machine Learning
There are several files in the output directory.
```AccuracyBayes.txt``` is the accuracy value of Bayes Classification.
```AccuracyDT.txt``` is the accuracy value of Decision Tree.
```AccuracyLR.txt``` is the accuracy value of Logistic Regression.
```AccuracyOneVsRest.txt``` is the accuracy value of One vs Rest based on Logistic Regression.
```AccuracyRF.txt``` is the accuracy value of Random Forest.
If you want to save the model, please uncomment the corresponding line

### Terminal Commands - mlCompilation.py
Execute all machine learning operations in a row.
Example usage:
The command line parameter ```--dirName Directory``` is a repository for reading the cleaned data ```ml sample``` and saving the results of machine learning.
```bash
spark-submit mlCompilation.py --dirName Result
```

### Terminal Commands - Single Machine Learning Algorithm
Single machine learning algorithms can be executed individually as the required input file is in the output repository. 
Example usage:
The command line parameter ```--dirName Directory``` is a repository for reading the cleaned data ```ml sample``` and saving the results of machine learning.
```bash
spark-submit *mlAlgorithm*.py --dirName Result
```

If you meet any problem on running, please email to the leader scyzw1@nottingham.edu.cn.
# Spark_Spain_train
